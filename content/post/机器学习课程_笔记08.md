---
title: 机器学习课程_笔记08
date: 2017-06-16 22:00:00+08:00
author: 徐新杰
tags:
  - 机器学习
  - andrew ng
categories:
  - 机器学习
---

## 核（Kernels）

SVM算法的原理如下：

`
$$
min \frac 1 2 ||w||^2 \\
s. t. y^{(i)}(W^TX^{(i)} + b) >= 1
$$
`

上述式子的对偶问题如下：
`
$$
max\sum_i\alpha_i - \frac 1 2 \sum_i \sum_j y^{(i)}y^{(j)} \alpha_i \alpha_j <X^{(i)}, X^{(j)}> \\
s. t. \alpha_i>=0, \sum_iy_i\alpha_i=0 \\
W = \sum_i\alpha_iy^{(i)}X^{(i)}
$$
`

## 软间隔SVM

## SMO算法
